---
layout: post
date: '2018-03-24 18:32 -0400'
author: Jon Brown
permalink: /blog/ibm-machine-learning-integration/
published: true
type: BlogPosting
title: Apple Expands Partnership with IBM to Integrate New Machine Learning
tagline: Apple Expands Partnership with IBM to Integrate New Machine Learning
tags:
  - mac
  - ios
categories:
  - news
image: /assets/images/covers/2018/watsonceo.jpg
thumbnail: /assets/images/covers/2018/watsonceo.jpg
link: /assets/app-images/2018/watsonceo.jpg
cta: 4
custom_js:
- js/validate
- js/contactform
- js/alertify
- js/custom
comments: true
---
## Late Monday, Apple and IBM announced an expansion to their existing partnership to allow customers to use advanced in-app machine learning capabilities using IBM’s Watson and Apple’s Core ML technologies.

<img src="{{ site.site_cdn }}/assets/images/blog/2018/ibm/apple_ibm.png" class="img-fluid rounded m-2" width="700" />

The new expansion allows users to develop machine learning tools using Watson technology, called Watson Services for Core ML and then to deploy those assets on Apple mobile devices via MobileFirst apps. These services include analyzing images, classifying visual data and training models with Watson services.

Watson’s Visual Recognition capabilities provides pre-trained machine learning models for image analysis. This helps in recognizing objects, faces, scenes, food, color and more content. Images can be classified according to the user’s needs.

An example would using the integrated machine learning model in an iOS enterprise app where the user could use Watson’s image recognition capabilities to differentiate between a broken appliance or a functioning one. The model would also provide the technician using the app information such as the make and model. The technician could then ask the app to run a database query for repair parts, provide the next step diagnostics procedures, identify parts onscreen and even to determine potential problems. 

Adding Watson tech into iOS is straightforward. The user called a ‘client’ first builds a machine learning model with Watson that taps into an offsite data repository. The model is converted into Core ML, added into a custom app and then distributed through IBM's MobileFirst platform. 

Core ML was introduced by Apple at WWDC last  year and is a tool that helps integrate trained neural network models made via third party tools into an iOS app. This is part of Apple's entry into machine learning, which started with iOS 11 and the A11 Bionic chip. 

Apple and IBM first partnered in 2014 for MobileFirst enterprise solutions where IBM handles hardware leasing, device management, security, analytics, mobile integration and on-site repairs, while Apple aids in software development and customer support through AppleCare. IBM added Watson technology to the service two years ago, thus offering in-house API tools such as Natural Language Processing and Watson Conversation. The new machine learning capabilities are an extension of those efforts.

Several companies already use MobileFirst apps for business such as Banco Santander for banking solutions via apps.
